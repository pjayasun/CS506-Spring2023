{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 04\n",
    "\n",
    "Name: Pranesh Jayasundar\n",
    "UID: U08334002\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Distance & Similarity\n",
    "- Cost Functions\n",
    "- K means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance & Similarity\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "a) In the minkowski distance, describe what the parameters p and d are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p: is just a parameter, and p >= 1. When p = 2 it's Euclidean distance, and when p = 1 it's Manhattan distance. \"p\" is a positive integer that determines the power to which the distances between the elements are raised.\n",
    "- d: The parameter \"d\" represents the number of dimensions in the space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In your own words describe the difference between the Euclidean distance and the Manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Euclidean distance is the most commonly used distance metric and is the straight line distance between two points in a space. It is calculated as the square root of the sum of the squares of the differences between the coordinates of the two points\n",
    "\n",
    "- On the other hand, the Manhattan distance, when p = 1 in the minkowski distance, measures the sum of the absolute differences between the coordinates of the two points. It only takes into account the change in each dimension individually and is not sensitive to changes in other dimensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider A = (0, 0) and B = (1, 1). When:\n",
    "\n",
    "- p = 1, d(A, B) = 2\n",
    "- p = 2, d(A, B) = $\\sqrt{2} = 1.41$\n",
    "- p = 3, d(A, B) = $2^{1/3} = 1.26$\n",
    "- p = 4, d(A, B) = $2^{1/4} = 1.19$\n",
    "\n",
    "c) Describe what you think distance would look like when p is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I think, it might tend to become closer to 1, when \"p\" increases. Say when p = 100, it would be 1.001, and when p = 10000, the distance might be 1.00000001\n",
    "- We can basically come up with the intuition; any power of 1 ~ 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Is the minkowski distance still a distance function when p < 1? Expain why / why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No, it's not the distance function when p < 1 because it violates the distance function properties. Let's take three points A, B, C - (0, 0), (0, 1), (1, 0). The hypotenuse is greater than the sum of other two sides which violates the triangle inequality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) when would you use cosine similarity over the euclidan distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cosine similarity is used for text and document analysis, while Euclidean distance is used for finding the distance between points in a space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) what does the jaccard distance account for that the manhattan distance doesn't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jaccard distance takes into consideration the similar words or similarity, whereas the manhattan distance doesn't take the similarity. \n",
    "- Jaccard distance is calculated based on the similar words between 2 documents, and manhattan distance is the absolute difference between 2 sets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "\n",
    "Consider the following two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"hello my name is Alice\"  \n",
    "s2 = \"hello my name is Bob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the union of words from both sentences, we can represent each sentence as a vector. Each element of the vector represents the presence or absence of the word at that index.\n",
    "\n",
    "In this example, the union of words is (\"hello\", \"my\", \"name\", \"is\", \"Alice\", \"Bob\") so we can represent the above sentences as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = [1,    1, 1,   1, 1,    0]\n",
    "#     hello my name is Alice\n",
    "v2 = [1,    1, 1,   1, 0, 1]\n",
    "#     hello my name is    Bob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatically, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'hello', 'is', 'Bob', 'Alice']\n",
      "[1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus = [s1, s2]\n",
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)\n",
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a new sentence to our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"hi my name is Claude\"\n",
    "corpus.append(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the new union of words used to represent s1, s2, and s3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'hello', 'hi', 'is', 'Bob', 'Alice', 'Claude']\n"
     ]
    }
   ],
   "source": [
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Represent s1, s2, and s3 as vectors as above, using this new set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 0, 1, 0]\n",
      "[1, 1, 1, 0, 1, 1, 0, 0]\n",
      "[1, 1, 0, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "v2 = [1 if x in s2 else 0 for x in all_words]\n",
    "v3 = [1 if x in s3 else 0 for x in all_words]\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that computes the manhattan distance between two vectors. Which pair of vectors are the most similar under that distance function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between v1 and v2: 2\n",
      "Distance between v2 and v3: 4\n",
      "Distance between v1 and v3: 4\n"
     ]
    }
   ],
   "source": [
    "def manhattan_distane(x, y):\n",
    "    # To check x and y are of the same dimension\n",
    "    res = 0\n",
    "    for i in range (len(x)):\n",
    "        res += abs(x[i] - y[i])\n",
    "\n",
    "    return res\n",
    "\n",
    "print('Distance between v1 and v2:', manhattan_distane(v1, v2))\n",
    "print('Distance between v2 and v3:', manhattan_distane(v2, v3))\n",
    "print('Distance between v1 and v3:', manhattan_distane(v1, v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create a matrix of all these vectors (row major) and add the following sentences in vector form:\n",
    "\n",
    "- \"hi Alice\"\n",
    "- \"hello Claude\"\n",
    "- \"Bob my name is Claude\"\n",
    "- \"hi Claude my name is Alice\"\n",
    "- \"hello Bob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 1]\n",
      " [1 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 1 0 1 1]\n",
      " [0 0 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix for all the above mentioned vectors\n",
    "# {hi, Alice, hello, claude, Bob, my, name, is}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "s4 = \"hi Alice\"\n",
    "corpus.append(s4)\n",
    "\n",
    "s5 = \"hello Claude\"\n",
    "corpus.append(s5)\n",
    "\n",
    "s6 = \"Bob my name is Claude\"\n",
    "corpus.append(s6)\n",
    "\n",
    "s7 = \"hi Claude my name is Alice\"\n",
    "corpus.append(s7)\n",
    "\n",
    "s8 = \"hello Bob\"\n",
    "corpus.append(s8)\n",
    "\n",
    "\n",
    "v4 = [1 if x in s4 else 0 for x in all_words]\n",
    "\n",
    "v5 = [1 if x in s5 else 0 for x in all_words]\n",
    "\n",
    "v6 = [1 if x in s6 else 0 for x in all_words]\n",
    "\n",
    "v7 = [1 if x in s7 else 0 for x in all_words]\n",
    "\n",
    "v8 = [1 if x in s8 else 0 for x in all_words]\n",
    "\n",
    "matrix = []\n",
    "matrix.append(v4)\n",
    "matrix.append(v5)\n",
    "matrix.append(v6)\n",
    "matrix.append(v7)\n",
    "matrix.append(v8)\n",
    "\n",
    "matrix = np.array(matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) How many rows and columns does this matrix have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of the matrix is 5 x 8\n",
    "\n",
    "Rows: 5\n",
    "Columns: 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) When using the Manhattan distance, which two sentences are the most similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar sentences are sentence 2 and sentence 5\n"
     ]
    }
   ],
   "source": [
    "lowest_distance = manhattan_distane(v4, v5)\n",
    "most_similar = (1, 2) # By default\n",
    "\n",
    "for i in range(1, 6):\n",
    "    for j in range(i + 1, 6):\n",
    "        if manhattan_distane(matrix[i - 1], matrix[j - 1]) < lowest_distance:\n",
    "            lowest_distance = manhattan_distane(matrix[i - 1], matrix[j - 1])\n",
    "            most_similar = (i, j)\n",
    "\n",
    "            print('The most similar sentences are sentence', str(most_similar[0]), 'and sentence', str(most_similar[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration 1:\n",
    "\n",
    "(1) Step 1: Randomly pick k centers\n",
    "- Here the k value is 2, and the centers are [0, 2].\n",
    "\n",
    "(2) Step 2: Assign each point in the dataset to its closest center.\n",
    "- 0: assigned to center 0\n",
    "- 0.5: assigned to center 0\n",
    "- 1.5: assigned to center 2\n",
    "- 2: assigned to center 2\n",
    "- 6: assigned to center 2\n",
    "- 6.5: assigned to center 2\n",
    "- 7: assigned to center 2\n",
    "\n",
    "(3) Step 3: Compute the new centers as the means of each cluster\n",
    "- New mean: (0 + 0.5)/2 = 0.25\n",
    "- New mean: (1.5 + 2 + 6 + 6.5 + 7)/5 = 4.6\n",
    "\n",
    "New centroid: [0.25, 4.6]\n",
    "\n",
    "(4) Step 4: Repeat step 2 and 3 until convergence\n",
    "\n",
    "\n",
    "\n",
    "Iteration 2:\n",
    "\n",
    "(1) Step 1: Randomly pick k centers\n",
    "- Here the k value is 2, and the centers are [0.25, 4.6].\n",
    "\n",
    "(2) Step 2: Assign each point in the dataset to its closest center.\n",
    "- 0: assigned to center 0.25\n",
    "- 0.5: assigned to center 0.25\n",
    "- 1.5: assigned to center 0.25\n",
    "- 2: assigned to center 0.25\n",
    "- 6: assigned to center 4.6\n",
    "- 6.5: assigned to center 4.6\n",
    "- 7: assigned to center 4.6\n",
    "\n",
    "(3) Step 3: Compute the new centers as the means of each cluster\n",
    "- New mean: (0 + 0.5 + 1.5 + 2)/4 = 1\n",
    "- New mean: (6 + 6.5 + 7)/3 = 6.5\n",
    "\n",
    "New centroid: [1, 6.5]\n",
    "\n",
    "(4) Step 4: Repeat step 2 and 3 until convergence\n",
    "\n",
    "\n",
    "\n",
    "Iteration 3:\n",
    "\n",
    "(1) Step 1: Randomly pick k centers\n",
    "- Here the k value is 2, and the centers are [1, 6.5].\n",
    "\n",
    "(2) Step 2: Assign each point in the dataset to its closest center.\n",
    "- 0: assigned to center 1\n",
    "- 0.5: assigned to center 1\n",
    "- 1.5: assigned to center 1\n",
    "- 2: assigned to center 1\n",
    "- 6: assigned to center 6.5\n",
    "- 6.5: assigned to center 6.5\n",
    "- 7: assigned to center 6.5\n",
    "\n",
    "(3) Step 3: Compute the new centers as the means of each cluster\n",
    "- New mean: (0 + 0.5 + 1.5 + 2)/4 = 1\n",
    "- New mean: (6 + 6.5 + 7)/3 = 6.5\n",
    "\n",
    "New centroid: [1, 6.5]\n",
    "\n",
    "(4) Final, no more changes in the centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cost function for K-Means is a measure of how close each data point is to the center of its assigned cluster. \n",
    "- The algorithm tries to minimize this measure so that the clusters are tight and well defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initial centroid selection plays a huge role, (i.e) the 'k' random centers\n",
    "- Outliers can have a significant impact on the solution of K-Means. If there are outliers in the dataset, the algorithm may converge to a solution that is heavily influenced by them, rather than the actual cluster centers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does not always converge to a global optimum solution. \n",
    "- It can sometimes converge to a local minimum, which may not be the best solution for the given dataset.\n",
    "- The optimization process used by the K-Means algorithm can get stuck in a local minimum, where the cost function no longer decreases.\n",
    "- To overcome this problem, we can initialize random centroids multiple time, and run Lloyd's algorithm to improve the chances of finding a better solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
